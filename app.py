import os
import queue
import shutil
import subprocess
import tempfile
import threading
from datetime import datetime
from pathlib import Path

import streamlit as st

# --- C·∫§U H√åNH TRANG & CSS ---
st.set_page_config(
    page_title="Video Processor Pro", layout="wide", initial_sidebar_state="expanded"
)


# --- LOAD CSS ---
def load_css(file_name):
    with open(file_name) as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)


load_css("assets/style.css")

# --- KH·ªûI T·∫†O GLOBAL QUEUE & STATE ---
# Queue d√πng ƒë·ªÉ g·ª≠i k·∫øt qu·∫£ t·ª´ Thread x·ª≠ l√Ω v·ªÅ Main Thread
if "result_queue" not in st.session_state:
    st.session_state["result_queue"] = queue.Queue()

if "stop_event" not in st.session_state:
    st.session_state["stop_event"] = threading.Event()

if "processing_thread" not in st.session_state:
    st.session_state["processing_thread"] = None


# --- CORE FUNCTIONS (CH·∫†Y TRONG THREAD) ---
def process_video_task(
    input_path, output_path, platform, speed, options, queue_obj, stop_event
):
    """H√†m x·ª≠ l√Ω ch·∫°y trong thread ri√™ng v·ªõi c√°c hi·ªáu ·ª©ng n√¢ng cao"""

    if stop_event.is_set():
        return

    # --- 1. X√ÇY D·ª∞NG VIDEO FILTERS ---
    filters = []

    # a. Speed (Video)
    # setpts=PTS/speed
    filters.append(f"setpts=PTS/{speed}")

    # b. Platform Colors & Flip (C∆° b·∫£n)
    if platform == "TikTok":
        # Saturation 1.2, Contrast 1.05, Flip
        filters.append("eq=saturation=1.2:contrast=1.05")
        filters.append("hflip")
    else:
        # Brightness 0.05, Contrast 1.1, Flip
        filters.append("eq=brightness=0.05:contrast=1.1")
        filters.append("hflip")

    # c. Advanced Visual Options
    # Rotation (M·ªõi) - ƒê·∫∑t tr∆∞·ªõc Crop ƒë·ªÉ tr√°nh b·ªã ƒëen g√≥c n·∫øu combine
    rotate_angle = options.get("rotate", 0)
    if rotate_angle != 0:
        # Xoay v√† l·∫•p ƒë·∫ßy n·ªÅn ƒëen (tuy nhi√™n n·∫øu c√≥ crop sau ƒë√≥ th√¨ s·∫Ω c·∫Øt h·∫øt ƒëen)
        # S·ª≠ d·ª•ng ow, oh m·∫∑c ƒë·ªãnh s·∫Ω gi·ªØ nguy√™n k√≠ch th∆∞·ªõc khung h√¨nh nh∆∞ng b·ªã ƒëen g√≥c
        # PI = 3.141592653589793
        filters.append(f"rotate={rotate_angle}*PI/180")
    if options.get("zoom_crop"):
        # Zoom & Crop 10%: crop=iw*0.9:ih*0.9 -> scale=iw:ih
        filters.append("crop=iw*0.9:ih*0.9")
        filters.append("scale=iw:ih")

    if options.get("add_noise"):
        # Th√™m nhi·ªÖu h·∫°t nh·∫π: alls=10 (c∆∞·ªùng ƒë·ªô), allf=t (temporal noise)
        filters.append("noise=alls=10:allf=t+u")

    if options.get("vignette"):
        # Hi·ªáu ·ª©ng t·ªëi 4 g√≥c
        filters.append("vignette")

    # G·ªôp c√°c filter h√¨nh ·∫£nh th√†nh chu·ªói
    vf_string = ",".join(filters)

    # --- 2. X√ÇY D·ª∞NG AUDIO FILTERS ---
    # M·ª•c ti√™u: ƒê·∫°t ƒë∆∞·ª£c Video Speed y√™u c·∫ßu, ƒë·ªìng th·ªùi apply c√°c hi·ªáu ·ª©ng √¢m thanh
    audio_chains = []

    if not options.get("mute_audio"):
        # Logic t√≠nh to√°n Speed & Pitch
        # Video ƒëang ch·∫°y ·ªü t·ªëc ƒë·ªô = 'speed' (v√≠ d·ª• 1.05)
        # Audio ph·∫£i kh·ªõp t·ªëc ƒë·ªô n√†y.

        current_audio_speed = 1.0

        # a. Pitch Shifting (L√†m m√©o gi·ªçng)
        if options.get("pitch_shift"):
            # TƒÉng pitch l√™n 5% b·∫±ng c√°ch tƒÉng sample rate
            # ƒêi·ªÅu n√†y l√†m audio nhanh h∆°n 1.05 l·∫ßn
            pitch_factor = 1.05
            audio_chains.append(f"asetrate=44100*{pitch_factor},aresample=44100")
            current_audio_speed *= pitch_factor

        # b. Equalizer (C·∫Øt Bass - Low Cut)
        if options.get("low_bass"):
            # Gi·∫£m 10dB ·ªü t·∫ßn s·ªë 100Hz (Width type h = Hz)
            audio_chains.append("equalizer=f=100:width_type=h:width=200:g=-10")

        # c. Final Speed Adjustment (Atempo)
        # Ta c·∫ßn ƒë∆∞a t·ªëc ƒë·ªô audio v·ªÅ ƒë√∫ng b·∫±ng 'speed' c·ªßa video
        # H·ªá s·ªë c·∫ßn ƒëi·ªÅu ch·ªânh = speed_mong_mu·ªën / speed_hi·ªán_t·∫°i
        needed_tempo = speed / current_audio_speed

        # Atempo gi·ªõi h·∫°n t·ª´ 0.5 ƒë·∫øn 2.0. N·∫øu v∆∞·ª£t qu√° ph·∫£i chain nhi·ªÅu c√°i (nh∆∞ng ·ªü ƒë√¢y diff nh·ªè n√™n ch·∫Øc kh√¥ng sao)
        audio_chains.append(f"atempo={needed_tempo}")

    # --- 3. L·ªÜNH FFMPEG ---
    command = ["ffmpeg", "-i", str(input_path)]

    # Apply Video Filters
    command.extend(["-vf", vf_string])

    # Apply Audio Filters
    if options.get("mute_audio"):
        command.append("-an")  # No Audio
    else:
        af_string = ",".join(audio_chains)
        if af_string:
            command.extend(["-af", af_string])
        command.extend(["-c:a", "aac"])

    # Output Settings
    command.extend(["-y", "-c:v", "libx264", str(output_path)])

    # --- 4. EXECUTE ---
    try:
        # Ch·∫°y FFmpeg - map_metadata -1 ƒë·ªÉ x√≥a th√¥ng tin g·ªëc
        full_cmd = command[:3] + ["-map_metadata", "-1"] + command[3:]

        result = subprocess.run(full_cmd, capture_output=True, text=True)
        is_success = result.returncode == 0
        error_msg = result.stderr if not is_success else None
    except Exception as e:
        is_success = False
        error_msg = str(e)

    # 5. Generate Thumbnail n·∫øu th√†nh c√¥ng

    # 6. Send Result
    if not stop_event.is_set():
        result_data = {
            "type": "video_done" if is_success else "video_error",
            "filename": input_path.name,
            "output_name": output_path.name,
            "output_path": str(output_path),
            "thumb_path": None,
            "size": f"{os.path.getsize(output_path) / (1024 * 1024):.1f} MB"
            if is_success
            else "0 MB",
            "error": error_msg,
        }
        queue_obj.put(result_data)


def worker_main(
    file_paths,
    output_dir,
    platform,
    speed,
    options,
    result_queue,
    stop_event,
):
    """H√†m main c·ªßa Worker Thread - L·∫∑p qua list file"""
    total = len(file_paths)
    result_queue.put({"type": "start", "total": total})

    for i, input_path in enumerate(file_paths):
        if stop_event.is_set():
            break

        # B√°o ƒëang x·ª≠ l√Ω file n√†o
        result_queue.put(
            {"type": "processing", "index": i, "filename": input_path.name}
        )

        filename = input_path.name
        prefix = "tiktok" if platform == "TikTok" else "shorts"
        output_filename = f"{prefix}_{filename}"
        output_path = output_dir / output_filename
        output_path = output_dir / output_filename

        process_video_task(
            input_path,
            output_path,
            platform,
            speed,
            options,
            result_queue,
            stop_event,
        )

    result_queue.put({"type": "complete"})


def create_zip_archive(source_dir, output_filename):
    return shutil.make_archive(output_filename.replace(".zip", ""), "zip", source_dir)


# --- POPUP VIEW ---
@st.dialog("üé• Xem tr∆∞·ªõc Video", width="large")
def preview_modal(video_path, video_name):
    st.subheader(video_name)
    st.video(video_path)


# --- RENDER HELPER (FRAGMENT) ---
@st.fragment(run_every=1)
def display_results_fragment():
    """
    Fragment x·ª≠ l√Ω hi·ªÉn th·ªã k·∫øt qu·∫£ v√† c·∫≠p nh·∫≠t ti·∫øn ƒë·ªô Real-time.
    """
    is_running = st.session_state.get("is_running", False)

    # 1. POLL QUEUE (C·∫≠p nh·∫≠t tr·∫°ng th√°i)
    # L·∫•y tin nh·∫Øn t·ª´ worker thread ƒë·ªÉ update session_state
    if is_running:
        try:
            for _ in range(10):  # Batch process messages
                msg = st.session_state["result_queue"].get_nowait()

                if msg["type"] == "start":
                    st.session_state["progress_info"]["total"] = msg["total"]

                elif msg["type"] == "processing":
                    st.session_state["progress_info"]["current"] = msg["index"]
                    st.session_state["progress_info"]["status"] = msg["filename"]

                elif msg["type"] == "video_done":
                    st.session_state["processed_results"].append(
                        {
                            "name": msg["output_name"],
                            "path": msg["output_path"],
                            "thumb": msg["thumb_path"],
                            "size": msg["size"],
                        }
                    )
                    st.session_state["progress_info"]["current"] += 1

                elif msg["type"] == "video_error":
                    st.error(f"L·ªói x·ª≠ l√Ω {msg['filename']}: {msg['error']}")
                    st.session_state["progress_info"]["current"] += 1

                elif msg["type"] == "complete":
                    st.session_state["is_running"] = False
                    st.toast("üéâ ƒê√£ x·ª≠ l√Ω xong to√†n b·ªô video!", icon="‚úÖ")

                    # Auto scroll to results
                    st.markdown(
                        """
                        <script>
                            var element = window.parent.document.getElementById("results_section");
                            if (element) {
                                element.scrollIntoView({behavior: "smooth", block: "start"});
                            }
                        </script>
                        """,
                        unsafe_allow_html=True,
                    )
                    # KH√îNG g·ªçi st.rerun() ·ªü ƒë√¢y ƒë·ªÉ tr√°nh t·∫Øt popup
        except queue.Empty:
            pass

    # 2. HI·ªÇN TH·ªä TI·∫æN ƒê·ªò (Ngay trong fragment ƒë·ªÉ update m·ªói 1s)
    prog = st.session_state.get("progress_info", {})
    total = prog.get("total", 0)
    current = prog.get("current", 0)

    if total > 0:
        # T√≠nh %
        ratio = current / total
        st.progress(min(ratio, 1.0))

        if is_running:
            st.caption(
                f"‚è≥ ƒêang x·ª≠ l√Ω: **{prog.get('status', '...')}** ({current}/{total})"
            )
        else:
            st.caption(f"‚úÖ Ho√†n t·∫•t ({total}/{total})")

    # 3. HI·ªÇN TH·ªä DANH S√ÅCH K·∫æT QU·∫¢
    results = st.session_state["processed_results"]
    if not results:
        if is_running:
            st.info("‚è≥ ƒêang kh·ªüi ƒë·ªông m√°y l√†m video...")
        return

    # ZIP Download
    first_path = Path(results[0]["path"])
    zip_base = first_path.parent.parent / "all_videos"
    if not os.path.exists(f"{zip_base}.zip"):
        create_zip_archive(first_path.parent, str(zip_base))

    zip_name = f"{datetime.now().strftime('%y%m%d_%H%M%S')}_{len(results)}_videos.zip"
    with open(f"{zip_base}.zip", "rb") as f_zip:
        st.download_button(
            label=f"üì¶ T·∫£i t·∫•t c·∫£ ({len(results)} videos)",
            data=f_zip.read(),
            file_name=zip_name,
            mime="application/zip",
            type="primary",
            key=f"dl_all_{len(results)}",
        )

    # Grid Render
    # Grid Render
    # Mobile: cols=2 (Streamlit auto stacks), Desktop: cols=3 or 5 ƒë·ªÉ khung video ƒë·ªß l·ªõn
    cols_per_row = 5
    rows = [results[i : i + cols_per_row] for i in range(0, len(results), cols_per_row)]

    for row_idx, row in enumerate(rows):
        cols = st.columns(cols_per_row)
        for idx, item in enumerate(row):
            with cols[idx]:
                with st.container(border=True):
                    # Video Player
                    st.video(item["path"])

                    # Info
                    name = item["name"]
                    short_name = (name[:40] + "...") if len(name) > 40 else name
                    st.markdown(f"**{short_name}**", help=name)
                    st.caption(item["size"])

                    # Download Button only
                    suffix = f"{row_idx}_{idx}"
                    with open(item["path"], "rb") as f:
                        st.download_button(
                            "‚¨áÔ∏è T·∫£i xu·ªëng",
                            f,
                            file_name=name,
                            key=f"d_{suffix}_{name}",
                            use_container_width=True,
                        )


# --- MAIN APP ---
def main():
    if "processed_results" not in st.session_state:
        st.session_state["processed_results"] = []
    if "temp_obj" not in st.session_state:
        st.session_state["temp_obj"] = None
    if "is_running" not in st.session_state:
        st.session_state["is_running"] = False
    if "progress_info" not in st.session_state:
        st.session_state["progress_info"] = {"current": 0, "total": 0, "status": ""}

    st.title("üé¨ Video Tool Pro")

    # --- 1. SIDEBAR: C·∫§U H√åNH (SETTINGS) ---
    with st.sidebar:
        st.header("‚öôÔ∏è C·∫•u h√¨nh")
        is_disabled = st.session_state["is_running"]

        # A. Platform & Speed
        st.subheader("1. C∆° b·∫£n")
        platform = st.radio(
            "N·ªÅn t·∫£ng m·ª•c ti√™u (Platform)",
            ["TikTok", "YouTube Shorts"],
            disabled=is_disabled,
            help="Ch·ªçn n·ªÅn t·∫£ng ƒë·ªÉ √°p d·ª•ng b·ªô l·ªçc m√†u v√† k√≠ch th∆∞·ªõc video ph√π h·ª£p.",
        )

        st.caption(
            """
            ‚ÑπÔ∏è **Kh√°c bi·ªát x·ª≠ l√Ω:**
            - **TikTok**: L·∫≠t g∆∞∆°ng (Flip), tƒÉng ƒë·ªô b√£o h√≤a (Saturation), l√†m m√†u video r·ª±c r·ª° h∆°n.
            - **YouTube**: L·∫≠t g∆∞∆°ng (Flip), tƒÉng ƒë·ªô s√°ng (Brightness), l√†m video s√°ng r√µ h∆°n.
            """
        )

        default_speed = 1.05 if platform == "TikTok" else 1.02
        speed = st.slider(
            "T·ªëc ƒë·ªô ph√°t (Speed Control)",
            0.5,
            2.0,
            default_speed,
            0.05,
            disabled=is_disabled,
            help="TƒÉng/Gi·∫£m t·ªëc ƒë·ªô video. M·∫∑c ƒë·ªãnh: TikTok 1.05x, YouTube 1.02x ƒë·ªÉ tr√°nh tr√πng l·∫∑p n·ªôi dung.",
        )

        # B. Visual Options
        st.subheader("2. H√¨nh ·∫£nh (Visual)")
        opt_zoom = st.checkbox(
            "Zoom 10% & Crop",
            value=True,
            disabled=is_disabled,
            help="Ph√≥ng to video 10% r·ªìi c·∫Øt vi·ªÅn xung quanh. Gi√∫p lo·∫°i b·ªè watermark ·ªü c·∫°nh v√† thay ƒë·ªïi c·∫•u tr√∫c khung h√¨nh (Anti-frame check).",
        )
        opt_noise = st.checkbox(
            "L√†m nhi·ªÖu (Add Noise)",
            value=False,
            disabled=is_disabled,
            help="Ph·ªß m·ªôt l·ªõp nhi·ªÖu m·ªèng l√™n video. Gi√∫p thay ƒë·ªïi m√£ h√≥a t·ª´ng pixel, ch·ªëng qu√©t tr√πng l·∫∑p m√£ Hash (Digital Fingerprint).",
        )
        opt_vignette = st.checkbox(
            "Vignette (T·ªëi 4 g√≥c)",
            value=False,
            disabled=is_disabled,
            help="L√†m t·ªëi d·∫ßn 4 g√≥c video. Thay ƒë·ªïi bi·ªÉu ƒë·ªì √°nh s√°ng (Histogram) c·ªßa video ƒë·ªÉ kh√°c bi·ªát so v·ªõi g·ªëc.",
        )

        opt_rotate = st.slider(
            "Xoay nghi√™ng (ƒê·ªô)",
            -5,
            5,
            0,
            1,
            disabled=is_disabled,
            help="Xoay video m·ªôt g√≥c nh·ªè (-5 ƒë·∫øn 5 ƒë·ªô). R·∫•t hi·ªáu qu·∫£ ƒë·ªÉ tr√°nh kh·ªõp khung h√¨nh (Visual Match). N√™n d√πng k√®m Zoom & Crop ƒë·ªÉ tr√°nh vi·ªÅn ƒëen.",
        )

        # C. Audio Options
        st.subheader("3. √Çm thanh (Audio)")
        opt_pitch = st.checkbox(
            "ƒê·ªïi gi·ªçng (Pitch Shifting)",
            value=True,
            disabled=is_disabled,
            help="TƒÉng cao ƒë·ªô √¢m thanh (Pitch) l√™n 5%. Gi√∫p gi·ªçng n√≥i/√¢m nh·∫°c kh√°c ƒëi so v·ªõi b·∫£n g·ªëc ƒë·ªÉ tr√°nh qu√©t b·∫£n quy·ªÅn √¢m thanh (Audio Match).",
        )
        opt_bass = st.checkbox(
            "Gi·∫£m Bass (Low Cut)",
            value=False,
            disabled=is_disabled,
            help="C·∫Øt b·ªõt t·∫ßn s·ªë √¢m tr·∫ßm (Bass) d∆∞·ªõi 100Hz. L√†m thay ƒë·ªïi ph·ªï √¢m thanh.",
        )
        opt_mute = st.checkbox(
            "T·∫Øt ti·∫øng (Mute Audio)",
            value=False,
            disabled=is_disabled,
            help="Lo·∫°i b·ªè ho√†n to√†n √¢m thanh. An to√†n tuy·ªát ƒë·ªëi v·ªÅ b·∫£n quy·ªÅn √¢m nh·∫°c.",
        )

    # --- 2. MAIN CONTENT: UPLOAD & ACTION ---

    # Khu v·ª±c Upload: Gom v√†o Expander ƒë·ªÉ ti·∫øt ki·ªám di·ªán t√≠ch
    with st.expander("üìÇ K√©o th·∫£ ho·∫∑c Ch·ªçn Video ƒë·ªÉ x·ª≠ l√Ω", expanded=True):
        uploaded_files = st.file_uploader(
            "Upload Video (.mp4, .mov)",
            type=["mp4", "mov"],
            accept_multiple_files=True,
            disabled=is_disabled,
            label_visibility="collapsed",
        )
        if not uploaded_files:
            st.caption(
                "üëÜ H·ªó tr·ª£ ƒë·ªãnh d·∫°ng .mp4, .mov. C√≥ th·ªÉ ch·ªçn nhi·ªÅu file c√πng l√∫c."
            )
        else:
            st.caption(f"‚úÖ ƒê√£ ch·ªçn **{len(uploaded_files)}** video.")

    # Action Buttons
    if not st.session_state["is_running"]:
        if st.button(
            "üöÄ CH·∫†Y",
            type="primary",
            use_container_width=True,
            disabled=not uploaded_files,
        ):
            # START LOGIC
            if st.session_state["temp_obj"]:
                try:
                    st.session_state["temp_obj"].cleanup()
                except Exception:
                    pass

            # Gom options
            options = {
                "zoom_crop": opt_zoom,
                "add_noise": opt_noise,
                "vignette": opt_vignette,
                "mute_audio": opt_mute,
                "pitch_shift": opt_pitch,
                "low_bass": opt_bass,
                "rotate": opt_rotate,
            }

            st.session_state["processed_results"] = []
            st.session_state["is_running"] = True
            st.session_state["stop_event"].clear()
            st.session_state["progress_info"] = {
                "current": 0,
                "total": 0,
                "status": "Starting...",
            }

            # Setup Temp
            temp_obj = tempfile.TemporaryDirectory()
            st.session_state["temp_obj"] = temp_obj
            temp_path = Path(temp_obj.name)
            (temp_path / "input").mkdir()
            (temp_path / "output").mkdir()

            # Save Inputs
            file_paths = []
            for uf in uploaded_files:
                p = temp_path / "input" / uf.name
                with open(p, "wb") as f:
                    f.write(uf.getbuffer())
                file_paths.append(p)

            # Start Thread
            t = threading.Thread(
                target=worker_main,
                args=(
                    file_paths,
                    temp_path / "output",
                    platform,
                    speed,
                    options,
                    st.session_state["result_queue"],
                    st.session_state["stop_event"],
                ),
            )
            t.start()
            st.session_state["processing_thread"] = t
            st.rerun()
    else:
        if st.button("‚èπÔ∏è D·ª™NG", type="secondary", use_container_width=True):
            st.session_state["stop_event"].set()
            st.session_state["is_running"] = False
            st.rerun()
    # Results Layout
    # Create a column for results to place the anchor
    col_result = st.container()
    with col_result:
        # Anchor for scrolling
        st.markdown('<div id="results_section"></div>', unsafe_allow_html=True)
        if st.session_state["processed_results"] or st.session_state["is_running"]:
            display_results_fragment()
            # Inject JavaScript to scroll to the results section when processing is complete
            if (
                st.session_state["processed_results"]
                and not st.session_state["is_running"]
            ):
                st.markdown(
                    """
                    <script>
                        var element = document.getElementById('results_section');
                        if (element) {
                            element.scrollIntoView({behavior: 'smooth'});
                        }
                    </script>
                    """,
                    unsafe_allow_html=True,
                )


if __name__ == "__main__":
    main()
